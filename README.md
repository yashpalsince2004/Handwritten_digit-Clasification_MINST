
# ğŸ§  Handwritten Digit Classification using MNIST Dataset

A beginner-friendly deep learning project built with TensorFlow and Keras that demonstrates how to classify handwritten digits (0â€“9) using a simple neural network trained on the MNIST dataset.

---

## ğŸ“ Project Overview

This project is designed to classify grayscale images of handwritten digits from the MNIST dataset using a basic **feedforward neural network (FNN)**. The model uses TensorFlow and Keras for building, training, and evaluating the neural network, and visualizes the results using `matplotlib`.

---

## ğŸ“Œ Key Features

- ğŸ“š Loads the MNIST dataset (60,000 training + 10,000 test images)
- âš™ï¸ Preprocesses images by normalizing pixel values
- ğŸ§  Builds a simple neural network with:
  - 1 Flatten layer
  - 1 Dense hidden layer with ReLU activation
  - 1 Dense output layer with Softmax activation
- ğŸš€ Trains the model for 5 epochs
- ğŸ“Š Evaluates the model on the test set
- ğŸ–¼ Visualizes predictions with Matplotlib

---

## ğŸ› ï¸ Technologies Used

- Python ğŸ
- TensorFlow 2.x
- Keras API
- Matplotlib
- NumPy

---

## ğŸ§ª Dataset

**MNIST Handwritten Digit Dataset**  
Provided by: [Yann LeCun](http://yann.lecun.com/exdb/mnist/)  
- Images: 28Ã—28 grayscale
- Labels: 0 to 9 (digit classes)

Loaded using:

```python
from tensorflow import keras
(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()
```

---

## ğŸ§¾ Installation & Usage

### âœ… Prerequisites

Make sure you have the following installed:

```bash
python3 --version
pip install tensorflow matplotlib numpy
```

### â–¶ï¸ Run the Project

1. Clone the repository:

```bash
git clone https://github.com/your-username/handwritten-digit-classification.git
cd handwritten-digit-classification
```

2. Run the script:

```bash
python Day4_Handwritten_Digit_Classification_MNIST.py
```

---

## ğŸ§  Model Architecture

```text
Input: 28x28 image â†’ Flatten â†’ 784 neurons
â†“
Dense Layer: 256 neurons, ReLU
â†“
Output Layer: 10 neurons, Softmax
```

- **Loss Function**: Sparse Categorical Crossentropy
- **Optimizer**: Adam
- **Metrics**: Accuracy

---

## ğŸ“ˆ Sample Output

- Prints training and test accuracy.
- Displays an image with predicted and actual labels.

```bash
Training data shape: (60000, 28, 28)
Epoch 1/5
...
Test Accuracy: 0.974
```

ğŸ–¼ Then opens a window showing the first test image and prediction.

---

## ğŸ“Œ Sample Visualization

```python
plt.imshow(X_test[0], cmap='gray')
plt.title(f"Predicted: {tf.argmax(predictions[0]).numpy()}, Actual: {y_test[0]}")
plt.show()
```

---

## ğŸ“¤ Contributing

Contributions are welcome! If youâ€™d like to improve this model or add features like CNN, dropout, or save/load models:

1. Fork the repository
2. Create a new branch: `git checkout -b feature-name`
3. Commit your changes
4. Push to the branch: `git push origin feature-name`
5. Open a Pull Request

---

## ğŸ“„ License

This project is open-source and available under the [MIT License](LICENSE).

---

## ğŸ™‹â€â™‚ï¸ Author

**Yash**  
ğŸ“ Computer Science (AI/ML) Student  
ğŸŒ [LinkedIn](https://www.linkedin.com/in/yash-pal-since2004) | ğŸ§  Passionate about AI & Deep Learning
